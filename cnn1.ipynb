{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mathew22/tensorflow-tutorial/blob/master/cnn1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "TyvgZ-6XB2Ob",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#CNN on MNIST **data**"
      ]
    },
    {
      "metadata": {
        "id": "fFEVbs7Y_xbL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YVkZYJX7_5LH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# read mnist data\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True )\n",
        "\n",
        "\n",
        "# network parameters \n",
        "learning_rate = 0.0001\n",
        "epochs = 10\n",
        "batch_size = 50\n",
        "\n",
        "\n",
        "# input data to the network. First dimension is ket as 0 as the batch size \n",
        "x = tf.placeholder( tf.float32, [ None, 784] )\n",
        "\n",
        "# reshaping to 2d single channel. First dimension is -1 indicatinf the batch size\n",
        "x_shaped = tf.reshape( x, [ -1, 28,28, 1] )\n",
        "\n",
        "# placeholder for one hot encoded labels\n",
        "y = tf.placeholder( tf.float32, [ None, 10 ] )\n",
        "\n",
        "def create_conv_layer( input_data, num_input_channels, num_filters, filter_shape, pool_shape, name ):\n",
        "    \n",
        "    conv_filter_shape = [ filter_shape[0], filter_shape[1], num_input_channels, num_filters ]\n",
        "    \n",
        "    weights = tf.Variable(tf.truncated_normal(conv_filter_shape, stddev=0.03), name= name+'_W')\n",
        "    \n",
        "    bias = tf.Variable(tf.truncated_normal([num_filters]), name=name+'_b')\n",
        "    \n",
        "    # stride =[batch, height, width, channels]\n",
        "    out_layer = tf.nn.conv2d( input_data, weights, strides=[ 1, 1, 1, 1 ], padding='SAME' )\n",
        "    \n",
        "    out_layer += bias\n",
        "    \n",
        "    out_layer = tf.nn.relu( out_layer )\n",
        "    \n",
        "    # pooling\n",
        "    ksize = [ 1, pool_shape[0], pool_shape[1], 1]\n",
        "    strides = [ 1, 2, 2, 1]\n",
        "    \n",
        "    out_layer = tf.nn.max_pool( out_layer, ksize=ksize, strides=strides, padding='SAME' )\n",
        "    \n",
        "    return out_layer\n",
        "\n",
        "\n",
        "\n",
        "# convolutional layers\n",
        "layer_1 = create_conv_layer( x_shaped, 1, 32, [ 5,5] ,[2,2], name='layer1' )\n",
        "layer_2 = create_conv_layer( layer_1 , 32, 64, [ 5,5] ,[2,2], name='layer2' )\n",
        "\n",
        "# fully connected layer \n",
        "flattened = tf.reshape( layer_2, [-1,7*7*64])\n",
        "\n",
        "\n",
        "w1 = tf.Variable(tf.truncated_normal( [7*7*64, 1000], stddev=0.03), name='w1' )\n",
        "b1 = tf.Variable( tf.truncated_normal([1000], stddev=0.01 ), name='b1')\n",
        "out_1 = tf.matmul( flattened, w1 ) + b1\n",
        "out_1 = tf.nn.relu( out_1 )\n",
        "\n",
        "w2 = tf.Variable(tf.truncated_normal( [1000, 10], stddev=0.03), name='w2' )\n",
        "b2 = tf.Variable( tf.truncated_normal([10],stddev=0.01), name='b2')\n",
        "out_2 = tf.matmul( out_1, w2 ) + b2\n",
        "y_cap = tf.nn.relu( out_2 )\n",
        "\n",
        "cross_entropy = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits( logits = out_2 , labels=y ) )\n",
        "\n",
        "optimizer =tf.train.AdamOptimizer( learning_rate=learning_rate).minimize( cross_entropy )\n",
        "\n",
        "correct_prediction = tf.equal( tf.argmax( y,1 ), tf.argmax( y_cap, 1))\n",
        "\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "init_op = tf.global_variables_initializer()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RAatVr6i__yC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    \n",
        "    sess.run( init_op )\n",
        "    total_batch = int( len( mnist.train.labels)/ batch_size)\n",
        "    for epoch in range( epochs):\n",
        "        avg_cost = 0\n",
        "        for i in range(total_batch):        \n",
        "            batch_x, batch_y = mnist.train.next_batch( batch_size=batch_size)\n",
        "            _, c = sess.run([optimizer, cross_entropy ], feed_dict={x:batch_x, y:batch_y })\n",
        "            avg_cost += c/total_batch\n",
        "        \n",
        "        test_acc = sess.run(accuracy,feed_dict={x: mnist.test.images, y: mnist.test.labels})        \n",
        "        print(\"Epoch:\", (epoch + 1), \"cost =\", \"{:.3f}\".format(avg_cost), \"test accuracy: {:.3f}\".format(test_acc))        \n",
        "    \n",
        "    print(\"\\nTraining complete!\")\n",
        "    print(sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels}))    \n",
        "                           \n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}